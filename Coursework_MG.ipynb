{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursework_MG.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiroGasparek/DeepLearningCourse/blob/master/Coursework_MG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CZdAvyqDk_rG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Coursework\n",
        "Based on the baseline code provided by the course instructors. The code introduces a two-step training for the N-HPatches problem, in which we aim to generate a patch descriptor that is able to perform successfully tasks such as matching, retrieval or verification.\n",
        "\n",
        "Contrary to classical HPatches dataset, in N-HPatches, images contain random non-smooth perturbations produced by a synthetic noise. This noise could be critical when training the descriptor, therefore, we introduce a denoising model that could help us to deal with those perturbations.\n",
        "\n",
        "Thus, we aim to minimize the noise in images before the second step, which is computing a feature vector, also called descriptor. Those descriptions must be a powerful representation of the input patches. The idea behind is that if two descriptors belong two similar patches, they should be close to each other, i.e. have a low Euclidean distance.\n",
        "\n",
        "This baseline code gives a method you can use to compare to whatever another approach you develop. There are several other approaches you can test to see if there is any improvement, e.g. train the descriptor directly with noisy patches, without the denoising model.\n",
        "\n",
        "## Safety checks\n",
        "\n",
        "As Google Colab is an external platform, we cannot guarantee that everytime you connect to a remote server, you will have the same amount of RAM or video RAM. For that reason, we will first check the amount of memory we have in the notebook. RAM should be around 12.9 GB, which is enough to load the datasets in memory. Also, usually, we have available 11.4 GB of GPU memory, which is more than enough to run this code.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UZLPUD3JlZOj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0ddb55c4-ba7e-40ab-d2a1-cae306406e9f"
      },
      "cell_type": "code",
      "source": [
        "# Taken from\n",
        "# https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# Colab only provides one GPU and it is not always guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5ce6bfbdb6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mGPUs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetGPUs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Colab only provides one GPU and it is not always guaranteed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprintm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mprocess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hYETGP-1mfGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "055b0363-4e1a-41d7-b507-9b511c3f7b93"
      },
      "cell_type": "code",
      "source": [
        "printm()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-abcb48d0db41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'printm' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "XkQ7gXSknn6g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading Functions and Data\n",
        "The first step is to clone the GitHub repository of the course, which contains already implemented functions. You can use your own function and import them here doing the same. In addition, we are going to download and extract the N-HPatches data.\n",
        "\n",
        "As a note, in colab, we can run terminal commands by using `!`. Also, by using `%` we have access to the built-in IPython magic commands, which we will use to move through directories (cd command). It takes around 5 minutes to download and unzip the dataset."
      ]
    },
    {
      "metadata": {
        "id": "lWbswTo_nxdI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "b6f39f05-2f20-43a5-c1f4-31181fbc1947"
      },
      "cell_type": "code",
      "source": [
        "# Clone repo\n",
        "!git clone https://github.com/MatchLab-Imperial/keras_triplet_descriptor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras_triplet_descriptor'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 169 (delta 19), reused 22 (delta 10), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (169/169), 149.84 MiB | 22.72 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Checking out files: 100% (69/69), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zWJ049SNn7pW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef77f13e-46f2-4b5e-b04e-b472f2e481ed"
      },
      "cell_type": "code",
      "source": [
        "# Change directory\n",
        "%cd /content/keras_triplet_descriptor"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras_triplet_descriptor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2-uLEr5QoCGY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "74467b2e-0b9c-42e6-ebeb-ac1d28345247"
      },
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "!wget -O hpatches_data.zip https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-18 22:00:56--  https://imperialcollegelondon.box.com/shared/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.box.com (imperialcollegelondon.box.com)... 107.152.27.197, 107.152.26.197\n",
            "Connecting to imperialcollegelondon.box.com (imperialcollegelondon.box.com)|107.152.27.197|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-02-18 22:00:56--  https://imperialcollegelondon.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Reusing existing connection to imperialcollegelondon.box.com:443.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip [following]\n",
            "--2019-02-18 22:00:56--  https://imperialcollegelondon.app.box.com/public/static/ah40eq7cxpwq4a6l4f62efzdyt8rm3ha.zip\n",
            "Resolving imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)... 107.152.26.199, 107.152.27.199\n",
            "Connecting to imperialcollegelondon.app.box.com (imperialcollegelondon.app.box.com)|107.152.26.199|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://public.boxcloud.com/d/1/b1!bs-EF-8Gwxkql2NTaMfmTj1yKANjk6JkwbQOep-m4_4yYUsRv6mvFXQ9KVDlpDAmnIm_xkco7tYB81AWyxUlOVPa0j0CNj3lzIVO431EFzG_pZ6FDyvK_PY-nJViBqNoucrEFV0w2qQgmca8inu-HTOqJFzfEfZWTwvStmr0Q_gArmGZVQBhBpQeCz2O5H7GNUVsuXVG1ZQZZ4uLdJoZQG5FlCZTGYq4w9Te1c0Fpiq7vTHggsrRsYj0hsNUe00lfVcCo1_DnI8X54ssAXiXqovYJmLZqcOb9n8j7OeKx_f0v2KYR4zX23zjrtuG3jIorEJeqmd3t7fKBey8uXajosaT7eiND68H1SjlL7zbjuZ5iVw8KeypLAWUm1GOVtt2wAO9GucnvVjDQV0N2SRztVLyoCS9-dBkN328AHgHX0lNVtA8NY9d_2fJUHsO-gD2jQ4yP9YMHfsPXy_38aBH2ysREUug6r1aRMKz_dMl7jJ707locqbwK5KhBSMk8xpoMpO280D-Pe3E4fjllQhBE_cpRfZ5ON4uV1i116y4p5XggX07ehwH1QfNye3H1C6LePXRWkquBcvbzeUj879WEPB-ZbMfl2_kYsQTsq61WRgQYEb8qMLaNXNh3EoDPli60TujaPTr8UBct9wjCnkmIElm4Up8PuOJgE241k_cWji0bZa8hBs_HXy1VA50GUL_pUCVNOdinUbWhsyc-_8EHeA8xyThY1rILEKHAxBBScnfbt2HV-c3tzO1GCFrG6ZmH_tW4WezcVnpLKWAOYjK7RgqnX43SOJ425QlAdfW6cQjzAvPNV7hrCXXJRbsTdwPr2xqSEmuR4XwCDhV2Jz49AbM5QekVCQ_RAnb4MfXbQ0q6kNi8kqZ-la5we2ztVQ_biBk8mveSrH_o6ERxZCt6PWxjty7yqNtB2r1KuqDazX2wXmFjs17LBQlmnPMyHpaQESvRLV8dgbBnGcwUX2RNd9f-KPIVLC_LaZ-mVesGku6E9CceBf9zRHYqXOpZiugwrtKMdOdGB_3jjn56VS0qvHVyaxLjUyE0FiFDVQVzSJWvb3HGkdhW_2jIway0YD6nGEc6DK1Qqg637PlcMi263R7Ya0NCS03codfU91ld_q_ROFarbwrTvvbSVwZTkdLMw3RiNrX7wtQwPPz4-UyBMtWdrV-MOgUDWvuEUlfUT0aCkufx96AfCBAlVmx4O5NQKJ71O2i_NWe7ZOcbDKjsEZJrGvvhIXb-VofxhHy444ZfWdx2tszm3PVRec2yoTb_AT61XUNnrrMcScTshbq_Q7VAvldYGdw2vVCsHF_ZqjfMIiFqhwbc-2hSDbEnYljTec3Gfz6owGdee5OMBRDEgnAOlr1HnvqVIX2HYo53dCoFeuARSCMkFSeTA2yUerowwDMGYTn6ja_EeJhxnMuEFGNJ3EWbu5ZUFfwR9GbHB3sza--aVM./download [following]\n",
            "--2019-02-18 22:00:57--  https://public.boxcloud.com/d/1/b1!bs-EF-8Gwxkql2NTaMfmTj1yKANjk6JkwbQOep-m4_4yYUsRv6mvFXQ9KVDlpDAmnIm_xkco7tYB81AWyxUlOVPa0j0CNj3lzIVO431EFzG_pZ6FDyvK_PY-nJViBqNoucrEFV0w2qQgmca8inu-HTOqJFzfEfZWTwvStmr0Q_gArmGZVQBhBpQeCz2O5H7GNUVsuXVG1ZQZZ4uLdJoZQG5FlCZTGYq4w9Te1c0Fpiq7vTHggsrRsYj0hsNUe00lfVcCo1_DnI8X54ssAXiXqovYJmLZqcOb9n8j7OeKx_f0v2KYR4zX23zjrtuG3jIorEJeqmd3t7fKBey8uXajosaT7eiND68H1SjlL7zbjuZ5iVw8KeypLAWUm1GOVtt2wAO9GucnvVjDQV0N2SRztVLyoCS9-dBkN328AHgHX0lNVtA8NY9d_2fJUHsO-gD2jQ4yP9YMHfsPXy_38aBH2ysREUug6r1aRMKz_dMl7jJ707locqbwK5KhBSMk8xpoMpO280D-Pe3E4fjllQhBE_cpRfZ5ON4uV1i116y4p5XggX07ehwH1QfNye3H1C6LePXRWkquBcvbzeUj879WEPB-ZbMfl2_kYsQTsq61WRgQYEb8qMLaNXNh3EoDPli60TujaPTr8UBct9wjCnkmIElm4Up8PuOJgE241k_cWji0bZa8hBs_HXy1VA50GUL_pUCVNOdinUbWhsyc-_8EHeA8xyThY1rILEKHAxBBScnfbt2HV-c3tzO1GCFrG6ZmH_tW4WezcVnpLKWAOYjK7RgqnX43SOJ425QlAdfW6cQjzAvPNV7hrCXXJRbsTdwPr2xqSEmuR4XwCDhV2Jz49AbM5QekVCQ_RAnb4MfXbQ0q6kNi8kqZ-la5we2ztVQ_biBk8mveSrH_o6ERxZCt6PWxjty7yqNtB2r1KuqDazX2wXmFjs17LBQlmnPMyHpaQESvRLV8dgbBnGcwUX2RNd9f-KPIVLC_LaZ-mVesGku6E9CceBf9zRHYqXOpZiugwrtKMdOdGB_3jjn56VS0qvHVyaxLjUyE0FiFDVQVzSJWvb3HGkdhW_2jIway0YD6nGEc6DK1Qqg637PlcMi263R7Ya0NCS03codfU91ld_q_ROFarbwrTvvbSVwZTkdLMw3RiNrX7wtQwPPz4-UyBMtWdrV-MOgUDWvuEUlfUT0aCkufx96AfCBAlVmx4O5NQKJ71O2i_NWe7ZOcbDKjsEZJrGvvhIXb-VofxhHy444ZfWdx2tszm3PVRec2yoTb_AT61XUNnrrMcScTshbq_Q7VAvldYGdw2vVCsHF_ZqjfMIiFqhwbc-2hSDbEnYljTec3Gfz6owGdee5OMBRDEgnAOlr1HnvqVIX2HYo53dCoFeuARSCMkFSeTA2yUerowwDMGYTn6ja_EeJhxnMuEFGNJ3EWbu5ZUFfwR9GbHB3sza--aVM./download\n",
            "Resolving public.boxcloud.com (public.boxcloud.com)... 107.152.27.200, 107.152.26.200\n",
            "Connecting to public.boxcloud.com (public.boxcloud.com)|107.152.27.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4088106554 (3.8G) [application/zip]\n",
            "Saving to: ‘hpatches_data.zip’\n",
            "\n",
            "hpatches_data.zip   100%[===================>]   3.81G  21.2MB/s    in 3m 7s   \n",
            "\n",
            "2019-02-18 22:04:05 (20.8 MB/s) - ‘hpatches_data.zip’ saved [4088106554/4088106554]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uac4VJgLq1nU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Extract data\n",
        "!unzip -q ./hpatches_data.zip\n",
        "!rm ./hpatches_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cur7xb3KrVNZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing Necessary Modules\n",
        "We now import the modules we will use in this baseline code."
      ]
    },
    {
      "metadata": {
        "id": "0PbKrRb5oFUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0241adb7-8367-4644-ebc8-8b0f82c4d26a"
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization \n",
        "from keras.layers import Input, UpSampling2D, concatenate  \n",
        "\n",
        "from read_data import HPatches, DataGeneratorDesc, hpatches_sequence_folder, DenoiseHPatches, tps\n",
        "from utils import generate_desc_csv, plot_denoise, plot_triplet"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "pk6xhMuNrwNK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Fix the seeds of the pseudo-random number generators to have reproducible results. The idea of fixing the seed is having the same results every time the algorithm is run if there are no changes in the code."
      ]
    },
    {
      "metadata": {
        "id": "-vGq5Urorbm8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fix random numbers generator\n",
        "random.seed(1234)\n",
        "np.random.seed(1234)\n",
        "tf.set_random_seed(1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgSHLP0JsE2g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we load the data. The original HPatches dataset has several splits, which are used to separate the available sequences in train sequences and test sequences. For our experiments in N-HPatches we use the same splits as in HPatches. Specifically, we load (and report results) using the split 'a':"
      ]
    },
    {
      "metadata": {
        "id": "tzw9KBQYsApi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hpatches_dir = './hpatches'\n",
        "splits_path = './splits.json'\n",
        "\n",
        "splits_json = json.load(open(splits_path, 'rb'))\n",
        "split = splits_json['a']\n",
        "\n",
        "train_fnames = split['train']\n",
        "test_fnames = split['test']\n",
        "\n",
        "seqs = glob.glob(hpatches_dir+'/*')\n",
        "seqs = [os.path.abspath(p) for p in seqs]   \n",
        "seqs_train = list(filter(lambda x: x.split('/')[-1] in train_fnames, seqs)) \n",
        "seqs_test = list(filter(lambda x: x.split('/')[-1] in split['test'], seqs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jtJUiKYDsIrL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}